{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65TOTJBV1pdX",
        "outputId": "fe2081f9-73d3-4d1b-9ecd-d460e8c27cc3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNiQZeDh4Xkl",
        "outputId": "1f4891ae-9341-4e5c-db4e-d508dfbd8415"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install fairseq\n",
        "!pip install fastBPE"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.11.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.19)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: fairseq in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq) (4.62.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.9.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.19.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.6)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.1.1)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.14.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.29.24)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq) (2019.12.20)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq) (2.0.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.9)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.4.4)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.3.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq) (2.20)\n",
            "Requirement already satisfied: omegaconf==2.1.* in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (2.1.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (5.2.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (4.8)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.1.*->hydra-core->fairseq) (5.4.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core->fairseq) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq) (3.7.4.3)\n",
            "Requirement already satisfied: fastBPE in /usr/local/lib/python3.7/dist-packages (0.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynmdz9ZHzjZ7",
        "outputId": "09af35ad-62f2-4581-bd45-0d6cd4d3b324"
      },
      "source": [
        "!git clone https://github.com/vncorenlp/VnCoreNLP\n",
        "!pip install vncorenlp"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VnCoreNLP'...\n",
            "remote: Enumerating objects: 215, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 215 (delta 0), reused 0 (delta 0), pack-reused 212\u001b[K\n",
            "Receiving objects: 100% (215/215), 214.22 MiB | 30.14 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n",
            "Collecting vncorenlp\n",
            "  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 10.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vncorenlp) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2.10)\n",
            "Building wheels for collected packages: vncorenlp\n",
            "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645951 sha256=da404c267ad8f1ec957af22c4194643b4787d43d1be7a2da038aac5d4bffd9b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/d8/f2/d28d97379b4f6479bf51247c8dfd57fa00932fa7a74b6aab29\n",
            "Successfully built vncorenlp\n",
            "Installing collected packages: vncorenlp\n",
            "Successfully installed vncorenlp-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jiA5nJZzZ1J"
      },
      "source": [
        "from transformers import RobertaForSequenceClassification, RobertaConfig\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from fairseq.data.encoders.fastbpe import fastBPE\n",
        "from fairseq.data import Dictionary\n",
        "from vncorenlp import VnCoreNLP\n",
        "import pandas as pd\n",
        "import argparse\n",
        "import torch\n",
        "import re"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vyyb9SI-ULuV"
      },
      "source": [
        "path_config  = '/content/drive/MyDrive/BERT/Config/config.json'\n",
        "path_model = '/content/drive/MyDrive/BERT/Config/pytorch_model.bin'\n",
        "path_bpe = '/content/drive/MyDrive/BERT/Config/bpe.codes'\n",
        "path_vocab = '/content/drive/MyDrive/BERT/Config/dict.txt'\n",
        "\n",
        "def get_model(path_model= None, path_config = None, path_bpe = None, path_vocab = None):\n",
        "  config = RobertaConfig.from_pretrained(\n",
        "      path_config, from_tf=False, num_labels = 3, output_hidden_states=False,\n",
        "  )\n",
        "  BERT_SA_NEW = RobertaForSequenceClassification.from_pretrained(\n",
        "      path_model,\n",
        "      config=config\n",
        "  )\n",
        "  BERT_SA_NEW.cuda()\n",
        "  BERT_SA_NEW.eval()\n",
        "\n",
        "\n",
        "  try:\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--bpe-codes', \n",
        "        default=path_bpe,\n",
        "        required=False,\n",
        "        type=str,\n",
        "        help='path to fastBPE BPE'\n",
        "    )\n",
        "    args, unknown = parser.parse_known_args()\n",
        "    bpe = fastBPE(args)\n",
        "  except:\n",
        "    bpe = None\n",
        "    print(\"load bpe fail\")\n",
        "\n",
        "  try:\n",
        "    vocab = Dictionary()\n",
        "    vocab.add_from_file(path_vocab)\n",
        "  except:\n",
        "    vocab=None\n",
        "    print('load vocab fail')\n",
        "  return BERT_SA_NEW, bpe, vocab\n",
        "\n",
        "model, bpe, vocab = get_model(path_model, path_config, path_bpe, path_vocab)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYP5tUsUTqH0"
      },
      "source": [
        "rdrsegmenter = VnCoreNLP(\"VnCoreNLP/VnCoreNLP-1.1.1.jar\", annotators=\"wseg,pos,ner\", max_heap_size='-Xmx2g')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW4reS4J00J_"
      },
      "source": [
        "macp = pd.read_excel('/content/Macp.xlsx')\n",
        "macp = macp.dropna()\n",
        "tenct = macp['Tên Công ty'].tolist()\n",
        "for i in range(len(tenct)):\n",
        "  tenct[i] = str(tenct[i]).lower()\n",
        "tenct[:5]\n",
        "tenma = macp['Mã '].tolist()\n",
        "\n",
        "def del_test(text):\n",
        "  year = ['năm 2021', 'năm 2020', 'năm 2019', 'năm 2018', 'năm 2017', 'năm 2016', 'năm 2015', 'năm 2014', 'năm 2013', 'năm 2012', 'năm 2011', 'năm 2010', 'Năm 2021', 'Năm 2020', 'Năm 2019', 'Năm 2018', 'Năm 2017', 'Năm 2016', 'Năm 2015', 'Năm 2014', 'Năm 2013', 'Năm 2012', 'Năm 2011', 'Năm 2010', '2021', '2020', '2019', '2018', '2017', '2016', '2015', '2014', '2013', '2012', '2011', '2010']\n",
        "  month = ['tháng 1', 'tháng 2', 'tháng 3', 'tháng 4', 'tháng 5', 'tháng 6', 'tháng 7', 'tháng 8', 'tháng 9', 'tháng 10', 'tháng 11', 'tháng 12', 'Tháng 1', 'Tháng 2', 'Tháng 3', 'Tháng 4', 'Tháng 5', 'Tháng 6', 'Tháng 7', 'Tháng 8', 'Tháng 9', 'Tháng 10', 'Tháng 11', 'tháng 12']\n",
        "  quy = ['quý 1', 'quý 2', 'quý 3', 'quý 4', 'Quý 1', 'Quý 2', 'Quý 3', 'Quý 4']\n",
        "  text = text.replace('Covid-19', 'Covid')\n",
        "  word_segmented_text = rdrsegmenter.ner(text)[0]\n",
        "  for char, typ in word_segmented_text:\n",
        "    if typ == 'B-ORG' or typ == 'I-ORG' or typ == 'B-PER' or typ == 'I-PER':\n",
        "      char = char.replace('_', ' ')\n",
        "      text = text.replace(char, 'name')\n",
        "    if typ == \"B-LOC\" or typ == \"I-LOC\":\n",
        "      if char != 'VN':\n",
        "        char = char.replace('_', ' ')\n",
        "        text = text.replace(char,'loc')\n",
        "    if typ == 'O':\n",
        "      if len(re.findall('\\d*\\.?\\,?\\d+\\%', char)) > 0:\n",
        "        text = text.replace(char, 'percent')\n",
        "      if len(re.findall('\\s?\\(?[A-Z]{3,4}\\)?\\s?', char)) > 0 and char != 'USD':\n",
        "          text = text.replace(char, 'name')\n",
        "      if char in tenma:\n",
        "        text = text.replace(char, 'name')\n",
        "      char = char.replace('_', ' ')\n",
        "      char_lower = char.lower()\n",
        "      if char_lower in tenct:\n",
        "        text = text.replace(char, 'name')\n",
        "  text = text.replace('\"', '')\n",
        "  text = text.replace('”', '')\n",
        "  text = text.replace('“', '')\n",
        "  text = text.replace('.', '')\n",
        "  text = text.replace(',', '')\n",
        "  text = text.replace('(', '')\n",
        "  text = text.replace(')', '')\n",
        "  text = text.replace(':', '')\n",
        "  text = text.replace('[', '')\n",
        "  text = text.replace(']', '')\n",
        "  text = text.replace('-', ' ')\n",
        "  text = re.sub('\\d{0,2}-?\\d{0,2}\\/\\d{1,4}', 'date', text)\n",
        "  for i in quy:\n",
        "    text = text.replace(i, 'date')\n",
        "  for i in year:\n",
        "    text = text.replace(i, 'date')\n",
        "  for i in month:\n",
        "    text = text.replace(i, 'date')\n",
        "  text = re.sub('\\d+ năm ', 'date ', text)\n",
        "  text = re.sub('\\d+ tháng ', 'date ', text)\n",
        "  text = re.sub(' \\-?\\d+\\w?', ' number', text)\n",
        "  text = text.split()\n",
        "  for i in range(len(text)):\n",
        "    if text[i].isdigit():\n",
        "      text[i] = 'number'\n",
        "  text = ' '.join(text)\n",
        "  text1 = text.split()\n",
        "  for i in range(len(text1)+1):\n",
        "    try:\n",
        "      if text1[i][0].isupper() and text1[i+1][0].isupper():\n",
        "        text = text.replace(text1[i], 'name')\n",
        "        text = text.replace(text1[i+1], 'name')\n",
        "    except:\n",
        "      pass\n",
        "  text = rdrsegmenter.tokenize(text)\n",
        "  text = ' '.join([' '.join(x) for x in text])\n",
        "  text = text.lower()\n",
        "  return text"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ohMK4yDy9e8"
      },
      "source": [
        "def predict(model, bpe, sense, vocab):\n",
        "  subwords = '<s> ' + bpe.encode(sense) + ' </s>'\n",
        "  encoded_sent = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long().tolist()\n",
        "  encoded_sent = pad_sequences([encoded_sent], maxlen=195, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "  mask = [int(token_id > 0) for token_id in encoded_sent[0]]\n",
        "\n",
        "\n",
        "  encoded_sent = torch.tensor(encoded_sent).cuda()\n",
        "  mask = torch.tensor(mask).cuda()\n",
        "  encoded_sent = torch.reshape(encoded_sent, (1, 195))\n",
        "  mask = torch.reshape(mask, (1, 195))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(encoded_sent, \n",
        "      token_type_ids=None, \n",
        "      attention_mask=mask)\n",
        "    logits = outputs[0]\n",
        "  return int(torch.argmax(logits))\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f1tSTl1zBr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "357a8b6a-b257-4004-f92b-8a6e6807e103"
      },
      "source": [
        "sent = 'VIC tăng mạnh, giá trị cổ phiếu tỷ phú Phạm Nhật Vượng nắm giữ đạt xấp xỉ 220.000 tỷ đồng'\n",
        "predict(model, bpe, sent, vocab)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}